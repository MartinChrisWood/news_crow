{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First approach;  summarise text using the TextRank algorithm\n",
    "\n",
    "This is adapted from the tutorial at https://www.analyticsvidhya.com/blog/2018/11/introduction-text-summarization-textrank-python/.  This is a single-domain-multiple-documents summarization task, it assumes that similar documents have already been isolated/grouped, and it is only seeing a single cohesive group.\n",
    "\n",
    "To be tried in future:\n",
    "- FastText rather than GloVe word embeddings\n",
    "- Some kind of native sentence embedding\n",
    "- The clustering-based extractive summarization at link below\n",
    "\n",
    "https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/martin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/martin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download various corpora/dictionaries for nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Download the glove word embeddings\n",
    "# Only do this once!\n",
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & clean text article\n",
    "\n",
    "Idea for the particular problem/source and specific regexes taken from https://stackabuse.com/text-summarization-with-nltk-in-python/.\n",
    "\n",
    "Article on articifial intelligence from Wiki https://en.wikipedia.org/wiki/Artificial_intelligence.  I just copy-pasted chunks, because I didn't want to complicate this trial with the BeautifulSoup details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals. Computer science defines AI research as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"wiki_ai.txt\", \"r\") as f:\n",
    "    article_text = f.read()\n",
    "\n",
    "article_text[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals. Computer science defines AI research as the study of intelligent agents: any device that perceives its environment and takes actions that maximize its chance of successfully achieving its g'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "article_text = re.sub(r'\\s+', ' ', article_text)\n",
    "article_text = re.sub(r'\"', '', article_text)\n",
    "article_text[0:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Separate and clean sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieved sentences:  444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals.',\n",
       " 'Computer science defines AI research as the study of intelligent agents: any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.',\n",
       " 'More in detail, Kaplan and Haenlein define AI as “a system’s ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation”.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(article_text)\n",
    "print(\"Number of retrieved sentences: \", len(sentences))\n",
    "sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer science, artificial intelligence (ai), sometimes called machine intelligence, intelligence demonstrated machines, contrast natural intelligence displayed humans animals.',\n",
       " 'computer science defines ai research study intelligent agents: device perceives environment takes actions maximize chance successfully achieving goals.',\n",
       " 'detail, kaplan haenlein define ai “a system’s ability correctly interpret external data, learn data, use learnings achieve specific goals tasks flexible adaptation”.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(sen):\n",
    "    return( \" \".join([word for word in sen.split() if word not in stopwords.words('english')]))\n",
    "\n",
    "clean_sentences = [remove_stopwords( s.replace('[^a-zA-Z]', ' ').lower() ) for s in sentences]\n",
    "clean_sentences[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate sentence vectors using glove word embeddings\n",
    "\n",
    "This is for measuring sentence similarity - it works by taking keywords and finding the word embeddings, then summing all the word embeddings within a given sentence, to create a sentence embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = {}\n",
    "\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    \n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        \n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        \n",
    "        word_embeddings[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49707  ,  0.23149  ,  0.40713  , -0.45075  , -0.19791  ,\n",
       "        0.30654  , -0.063001 ,  0.27542  , -0.15643  , -0.47526  ,\n",
       "        0.41297  ,  0.27763  ,  0.29307  ,  0.030136 ,  0.29642  ,\n",
       "       -0.057653 ,  0.33991  , -0.10233  ,  0.4065   ,  0.7054   ,\n",
       "        0.034193 ,  0.14666  , -0.81687  ,  0.08946  ,  0.7575   ,\n",
       "        0.65597  , -0.73024  ,  0.032863 ,  1.3157   , -0.043748 ,\n",
       "        0.028642 ,  0.48142  ,  1.0793   ,  0.21798  ,  0.0014403,\n",
       "       -0.12771  ,  0.33855  , -0.3514   ,  0.41824  , -0.78994  ,\n",
       "       -0.0030977, -0.33855  , -0.099491 , -0.092215 , -0.41304  ,\n",
       "        0.16718  , -0.29054  ,  0.2469   ,  0.21102  , -0.61423  ,\n",
       "       -0.34532  , -0.12433  ,  0.67826  ,  0.12531  , -0.26019  ,\n",
       "       -1.0047   , -0.21648  ,  0.61789  ,  0.04159  ,  0.13253  ,\n",
       "       -0.10514  ,  0.74716  , -0.57906  , -0.8061   ,  0.081409 ,\n",
       "       -0.19144  ,  0.08183  ,  0.44171  , -0.11134  , -1.1417   ,\n",
       "       -0.21043  ,  0.077252 ,  0.12823  , -0.79143  ,  0.073756 ,\n",
       "        1.4185   ,  0.082095 ,  0.23984  , -0.11158  , -0.30714  ,\n",
       "        0.40443  , -0.19225  ,  0.6104   ,  0.26731  , -0.90256  ,\n",
       "        0.082331 , -0.096697 , -0.1316   , -0.068099 ,  0.23911  ,\n",
       "        0.018046 ,  0.40787  ,  0.65384  ,  0.67642  , -0.035456 ,\n",
       "       -0.50215  , -0.021137 ,  0.71848  , -0.68097  ,  0.42033  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example word embedding\n",
    "word_embeddings['goodbye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentence_vectors = []\n",
    "\n",
    "for s in clean_sentences:\n",
    "    if len(s) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in s.split()]) / ( len(s.split()) + 0.001 )\n",
    "    \n",
    "    else:\n",
    "        v = np.zeros((100, ))\n",
    "    \n",
    "    clean_sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10143692,  0.1497839 ,  0.20410766,  0.05169257,  0.07655364,\n",
       "       -0.1374847 , -0.04935081, -0.14452541,  0.01069668,  0.13761435,\n",
       "        0.03155492, -0.27092878,  0.30302594,  0.04063247,  0.18868743,\n",
       "        0.22012094,  0.17044342,  0.11369723, -0.21930726,  0.00589068,\n",
       "       -0.01255586, -0.16933864,  0.1564537 , -0.28184678, -0.11547442,\n",
       "        0.00393545, -0.03242698,  0.0220843 , -0.02674257,  0.0818908 ,\n",
       "        0.192553  ,  0.28410211, -0.39706817, -0.13418555,  0.2363252 ,\n",
       "       -0.03458164, -0.19452069,  0.15324204,  0.1308446 , -0.01333038,\n",
       "       -0.10377957, -0.15500956, -0.1518354 , -0.00741159,  0.01889252,\n",
       "       -0.10405   ,  0.16874841,  0.00645233, -0.12718376, -0.31850214,\n",
       "        0.32251486,  0.0064132 ,  0.30856701,  0.69100994,  0.092877  ,\n",
       "       -1.1390456 ,  0.03049675, -0.09518538,  0.78377701,  0.17820066,\n",
       "        0.05150691,  0.51316704,  0.06775952, -0.07132871,  0.29580481,\n",
       "        0.05377457,  0.11555269, -0.12284428,  0.30812029,  0.2108344 ,\n",
       "        0.10342259,  0.04531748,  0.09874462, -0.18276285,  0.03121549,\n",
       "        0.00254986,  0.08051275,  0.0211611 , -0.48746076,  0.23035342,\n",
       "        0.48410978,  0.03879236, -0.33092423,  0.04052736, -1.09257598,\n",
       "        0.10717744,  0.38339947,  0.06403083, -0.05435131, -0.20527404,\n",
       "        0.09340237, -0.07391189, -0.02032781,  0.18873123, -0.10872227,\n",
       "       -0.06441103, -0.30507306, -0.57736516,  0.30451986,  0.10781639])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentence_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b.  Create Doc2Vec embeddings for each sentence using a pre-trained model\n",
    "\n",
    "I'll first be using a Doc2Vec model trained on the english wikipedia available from https://ibm.ent.box.com/s/3f160t4xpuya9an935k84ig465gvymm2.  Note;  there's a chance this AI demo page is in the model - but that's ok, this is just a demo.  Model was created for publication Han and Baldwin, 2016, \"An empirical evaluation of Doc2Vec with practical insights into document embedding generation\", https://arxiv.org/abs/1607.05368.\n",
    "\n",
    "I've taken the liberty of resaving the model, to future-proof changing formats/commands.\n",
    "\n",
    "The inferred vectors are of size 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:566: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "dbow = Doc2Vec.load(\"./enwiki_dbow/doc2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbow.save(\"./enwiki_dbow/doc2vec2.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference hyper-parameters\n",
    "start_alpha=0.01\n",
    "infer_epoch=1000\n",
    "\n",
    "clean_doc_vectors = []\n",
    "\n",
    "for s in clean_sentences:\n",
    "    if len(s) != 0:\n",
    "        v = dbow.infer_vector(s.split(), alpha=start_alpha, steps=infer_epoch)\n",
    "    \n",
    "    else:\n",
    "        v = np.zeros((dbow.vector_size, ))\n",
    "    \n",
    "    clean_doc_vectors.append(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TextRank Algorithm (applied to word2vec model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444, 444)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the cosine similarity between pairs of sentences\n",
    "sim_mat = cosine_similarity(clean_sentence_vectors)\n",
    "\n",
    "sim_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the similarity graph\n",
    "sim_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(sim_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i], s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0025384314329625793,\n",
       "  'Many researchers predict that such narrow AI work in different individual domains will eventually be incorporated into a machine with artificial general intelligence (AGI), combining most of the narrow skills mentioned in this article and at some point even exceeding human ability in most or all these areas.'),\n",
       " (0.00250385628270578,\n",
       "  'Some of the learners described below, including Bayesian networks, decision trees, and nearest-neighbor, could theoretically, if given infinite data, time, and memory, learn to approximate any function, including whatever combination of mathematical functions would best describe the entire world.'),\n",
       " (0.002497360627519849,\n",
       "  'The increased successes with real-world data led to increasing emphasis on comparing different approaches against shared test data to see which approach performed best in a broader context than that provided by idiosyncratic toy models; AI research was becoming more scientific.'),\n",
       " (0.002494813489506159,\n",
       "  \"Moravec's paradox generalizes that low-level sensorimotor skills that humans take for granted are, counterintuitively, difficult to program into a robot; the paradox is named after Hans Moravec, who stated in 1988 that it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility.\"),\n",
       " (0.0024932891177976103,\n",
       "  'Building a complete agent requires researchers to address realistic problems of integration; for example, because sensory systems give uncertain information about the environment, planning systems must be able to function in the presence of uncertainty.'),\n",
       " (0.0024897400220178427,\n",
       "  'Researchers at MIT (such as Marvin Minsky and Seymour Papert) found that solving difficult problems in vision and natural language processing required ad-hoc solutions—they argued that there was no simple and general principle (like logic) that would capture all the aspects of intelligent behavior.'),\n",
       " (0.0024867754142532095,\n",
       "  'By the 1980s, progress in symbolic AI seemed to stall and many believed that symbolic systems would never be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most representative 10 sentences\n",
    "ranked_sentences[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0015251645880050766,\n",
       "  'RNNs can be trained by gradient descent but suffer from the vanishing gradient problem.'),\n",
       " (0.001491896620595838,\n",
       "  'In 1989, Yann LeCun and colleagues applied backpropagation to such an architecture.'),\n",
       " (0.001410829874108621,\n",
       "  'Attendees Allen Newell (CMU), Herbert Simon (CMU), John McCarthy (MIT), Marvin Minsky (MIT) and Arthur Samuel (IBM) became the founders and leaders of AI research.'),\n",
       " (0.001361117484945754,\n",
       "  'Early pioneers also include Alexey Grigorevich Ivakhnenko, Teuvo Kohonen, Stephen Grossberg, Kunihiko Fukushima, Christoph von der Malsburg, David Willshaw, Shun-Ichi Amari, Bernard Widrow, John Hopfield, Eduardo R. Caianiello, and others.'),\n",
       " (0.0013017724882350284,\n",
       "  'champions, Brad Rutter and Ken Jennings, by a significant margin.'),\n",
       " (0.001292366421668597,\n",
       "  'This includes embodied, situated, behavior-based, and nouvelle AI.'),\n",
       " (0.00033848585343657686, 'In 2011, a Jeopardy!')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The least representative 10 sentences\n",
    "ranked_sentences[-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. TextRank Algorithm (applied to doc2vec model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444, 444)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the cosine similarity between pairs of sentences\n",
    "sim_mat = cosine_similarity(clean_doc_vectors)\n",
    "\n",
    "sim_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the similarity graph\n",
    "sim_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(sim_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i], s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.002965890800008051,\n",
       "  'They solve most of their problems using fast, intuitive judgements.'),\n",
       " (0.002906246989735876,\n",
       "  'Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.'),\n",
       " (0.0028779946842064025,\n",
       "  'Many learning algorithms use search algorithms based on optimization.'),\n",
       " (0.0028546425361181127,\n",
       "  'Computer vision is the ability to analyze visual input.'),\n",
       " (0.0028227424624113094,\n",
       "  'Several different forms of logic are used in AI research.'),\n",
       " (0.0027896476788019206,\n",
       "  'Evolutionary computation uses a form of optimization search.'),\n",
       " (0.0027880423325487443,\n",
       "  'robotics or machine learning), the use of particular tools (logic or artificial neural networks), or deep philosophical differences.')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most representative 10 sentences\n",
    "ranked_sentences[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0017463320009924639,\n",
       "  'The use of AI in banking can be traced back to 1987 when Security Pacific National Bank in US set-up a Fraud Prevention Task force to counter the unauthorised use of debit cards.'),\n",
       " (0.0017421548157783777,\n",
       "  'The third major approach, extremely popular in routine business AI applications, are analogizers such as SVM and nearest-neighbor: After examining the records of known past patients whose temperature, symptoms, age, and other factors mostly match the current patient, X% of those patients turned out to have influenza.'),\n",
       " (0.0017413034886258158,\n",
       "  'One project that is being worked on at the moment is fighting myeloid leukemia, a fatal cancer where the treatment has not improved in decades.'),\n",
       " (0.0017166138626555172,\n",
       "  'Progress slowed and in 1974, in response to the criticism of Sir James Lighthill and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI.'),\n",
       " (0.0016918600064689921,\n",
       "  'Clark also presents factual data indicating that error rates in image processing tasks have fallen significantly since 2011.'),\n",
       " (0.0016594806896695117,\n",
       "  'They can be nuanced, such as X% of families have geographically separate species with color variants, so there is an Y% chance that undiscovered black swans exist.'),\n",
       " (0.0002077920739973453, 'In 2011, a Jeopardy!')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The least representative 10 sentences\n",
    "ranked_sentences[-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions on extractive summarisation approach\n",
    "\n",
    "With the word2vec representation, the sentences most picked up on are, counter-intuitively, NOT those that give the most general overall description of AI.  Bearing in mind the full article content, which goes into reasonable if math-less technical detail, the top 10 sentences have instead picked out several important general technical points. The least representative sentences are generally shorter and contain more specific terminology/names.\n",
    "\n",
    "The doc2vec representation favours shorter sentences with more general terms, possibly document vectors represent unique meaning better than summed word vectors, which lead to long sentences incorporating many key words being favoured. The least representative sentences are generally longer but as with the word2vec approach go in to specific details that are not needed for a summary/overview.  Given our ultimate task, \"extract general descriptions of an unsupervised cluster's topic\", the second approach using doc2vec is probably wiser.  Neither method accurately produces what one might term an abstract or summary.\n",
    "\n",
    "\n",
    "### *Opening text of the Wiki Artificial Intelligence article, representing a \"human\" summary*\n",
    "\n",
    "> *In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals. Computer science defines AI research as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.[1] More in detail, Kaplan and Haenlein define AI as “a system’s ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation”.[2] Colloquially, the term \"artificial intelligence\" is applied when a machine mimics \"cognitive\" functions that humans associate with other human minds, such as \"learning\" and \"problem solving\".[3]*\n",
    "*The scope of AI is disputed: as machines become increasingly capable, tasks considered as requiring \"intelligence\" are often removed from the definition, a phenomenon known as the AI effect, leading to the quip in Tesler's Theorem, \"AI is whatever hasn't been done yet.\"[4] For instance, optical character recognition is frequently excluded from \"artificial intelligence\", having become a routine technology.[5] Modern machine capabilities generally classified as AI include successfully understanding human speech,[6] competing at the highest level in strategic game systems (such as chess and Go),[7] autonomously operating cars, and intelligent routing in content delivery networks and military simulations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
