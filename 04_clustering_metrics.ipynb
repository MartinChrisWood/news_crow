{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gauge how well the clusters separate the data\n",
    "\n",
    "#### Suggested approach:\n",
    "\n",
    "Coherence is not meant to work with clusters, only topics. It can only work with either \n",
    "- an existing LDA model, in which case it does something clever\n",
    "- A corpus, a dictionary and a list of [sets of?] key words representing topics\n",
    "\n",
    "To make models from different sources comparable, it could be quite tricky\n",
    "\n",
    "The other tool I could use is Silhouette scores, but they'll only work really for flat clustering models.\n",
    "\n",
    "TODO\n",
    "- Implement coherence against tokens\n",
    "- Implement Silhouette scoring against TF-IDF representations\n",
    "- Implement relevance scoring for retrieval of top tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import gensim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Useful flatten function from Alex Martelli on https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(df):\n",
    "    \"\"\" Helper, for printing basic info on corpus extent \"\"\"\n",
    "    \n",
    "    df['doc_size'] = df['clean_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    print(np.mean(df['doc_size']))\n",
    "    print(df.shape[0])\n",
    "    print(max(df['date']))\n",
    "    print(min(df['date']))\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword_stats(df, search_term_path = \"D:/Dropbox/news_crow/scrape_settings.json\"):\n",
    "    \"\"\"Retrive the set of search terms used for Bing, sum stories that contain them \"\"\"\n",
    "    with open(search_term_path, \"r\") as f:\n",
    "        scrape_config = json.load(f)\n",
    "        \n",
    "    search_terms = scrape_config['disaster_search_list']\n",
    "    search_terms = re.sub(r\"[^0-9A-Za-z ]\", \"\", \" \".join(search_terms)).lower().split()\n",
    "    search_terms = set(search_terms)\n",
    "    \n",
    "    term_results = {}\n",
    "    \n",
    "    for term in search_terms:\n",
    "        term_results[term] = sum(df['clean_text'].apply(lambda x: term in x.lower()))\n",
    "    \n",
    "    return(term_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_model_coherence(df, cluster_column=\"cluster\", tokens_column=\"tokens\"):\n",
    "    \"\"\" Helper, encapsulates entire coherence model-building process for (flat) models \"\"\"\n",
    "    # Create the vocabulary record\n",
    "    bow_dictionary = gensim.corpora.Dictionary(list(df[tokens_column]))\n",
    "    \n",
    "    # Create a BOW model\n",
    "    bow_corpus = [bow_dictionary.doc2bow(doc) for doc in df[tokens_column]]\n",
    "    \n",
    "    # Flattened list of all tokens for all documents for each \"topic\"\n",
    "    topics = {}\n",
    "    for topic in pd.unique(df['cluster']):\n",
    "        subset = df[df['cluster'] == topic]\n",
    "        topics[topic] = flatten(list(subset['tokens']))\n",
    "    \n",
    "    # Calculate ALL THE COHERENCE\n",
    "    coherences = {}\n",
    "    \n",
    "    cm = CoherenceModel(topics=list(topics.values()), texts=list(df['tokens']), dictionary=bow_dictionary, coherence='c_v')\n",
    "    coherences['c_v'] = cm.get_coherence()\n",
    "    \n",
    "    cm = CoherenceModel(topics=list(topics.values()), texts=list(df['tokens']), dictionary=bow_dictionary, coherence='c_npmi')\n",
    "    coherences['c_npmi'] = cm.get_coherence()\n",
    "    \n",
    "    cm = CoherenceModel(topics=list(topics.values()), corpus=bow_corpus, dictionary=bow_dictionary, coherence='u_mass')\n",
    "    coherences['u_mass'] = cm.get_coherence()\n",
    "        \n",
    "    return(coherences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing requirements of manual coherence scoring"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "topics = [\n",
    "     ['human', 'computer', 'system', 'interface'],\n",
    "     ['graph', 'minors', 'trees', 'eps']\n",
    "]\n",
    "\n",
    "cm = CoherenceModel(topics=topics, corpus=common_corpus, dictionary=common_dictionary, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create corpus, dictionary and lists of all tokens for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>source_url</th>\n",
       "      <th>retrieval_timestamp</th>\n",
       "      <th>origin</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>corpus_tfidf</th>\n",
       "      <th>cluster</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>West Midlands &lt;b&gt;flood&lt;/b&gt; warnings prompt &amp;#3...</td>\n",
       "      <td>Residents have been warned to &amp;quot;remain vig...</td>\n",
       "      <td>2019-11-17T17:35:00.0000000Z</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-50451817</td>\n",
       "      <td>www.bbc.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.278878</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>West Midlands flood warnings prompt ;remain vi...</td>\n",
       "      <td>[west, midland, flood, warn, prompt, remain, v...</td>\n",
       "      <td>[(0, 0.10888666697011559), (1, 0.1157487091387...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.320047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>New &lt;b&gt;flood&lt;/b&gt; warnings issued with more hom...</td>\n",
       "      <td>The Environment Agency has a number of &lt;b&gt;floo...</td>\n",
       "      <td>2019-11-17T18:35:00.0000000Z</td>\n",
       "      <td>https://www.hulldailymail.co.uk/news/hull-east...</td>\n",
       "      <td>www.hulldailymail.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.278928</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>New flood warnings issued with more homes at r...</td>\n",
       "      <td>[new, flood, warn, issu, home, risk, environ, ...</td>\n",
       "      <td>[(1, 0.237740646083191), (2, 0.118534432452920...</td>\n",
       "      <td>72</td>\n",
       "      <td>0.328762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>UK weather forecast – More than 100 &lt;b&gt;flood&lt;/...</td>\n",
       "      <td>&lt;b&gt;FLOOD&lt;/b&gt;-ravaged villages in the UK have b...</td>\n",
       "      <td>2019-11-17T13:45:00.0000000Z</td>\n",
       "      <td>https://www.thesun.co.uk/news/10342583/uk-weat...</td>\n",
       "      <td>www.thesun.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.278953</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>UK weather forecast – More than 100 flood aler...</td>\n",
       "      <td>[uk, weather, forecast, flood, alert, britain,...</td>\n",
       "      <td>[(2, 0.22914879635567142), (8, 0.1474814226459...</td>\n",
       "      <td>74</td>\n",
       "      <td>0.344483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>UK &lt;b&gt;flood&lt;/b&gt; warning map: &lt;b&gt;Flood&lt;/b&gt; chao...</td>\n",
       "      <td>The Environment Agency has issued 57 &lt;b&gt;flood&lt;...</td>\n",
       "      <td>2019-11-17T16:38:00.0000000Z</td>\n",
       "      <td>https://www.express.co.uk/news/weather/1205629...</td>\n",
       "      <td>www.express.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.279028</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>UK flood warning map: Flood chaos to continue ...</td>\n",
       "      <td>[uk, flood, warn, map, flood, chao, continu, t...</td>\n",
       "      <td>[(1, 0.13183366830610094), (2, 0.1314611473326...</td>\n",
       "      <td>72</td>\n",
       "      <td>0.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>UK weather forecast: &lt;b&gt;Flood&lt;/b&gt; chaos contin...</td>\n",
       "      <td>Despite some areas enduring their &amp;#39;wettest...</td>\n",
       "      <td>2019-11-17T18:32:00.0000000Z</td>\n",
       "      <td>https://www.mirror.co.uk/news/uk-news/uk-weath...</td>\n",
       "      <td>www.mirror.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.279047</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>UK weather forecast: Flood chaos continues wit...</td>\n",
       "      <td>[uk, weather, forecast, flood, chao, continu, ...</td>\n",
       "      <td>[(8, 0.1193340118121436), (9, 0.25139370146632...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.235525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node  index                                              title  \\\n",
       "0     0      0  West Midlands <b>flood</b> warnings prompt &#3...   \n",
       "1     1      1  New <b>flood</b> warnings issued with more hom...   \n",
       "2     2      2  UK weather forecast – More than 100 <b>flood</...   \n",
       "3     3      5  UK <b>flood</b> warning map: <b>Flood</b> chao...   \n",
       "4     4      6  UK weather forecast: <b>Flood</b> chaos contin...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Residents have been warned to &quot;remain vig...   \n",
       "1  The Environment Agency has a number of <b>floo...   \n",
       "2  <b>FLOOD</b>-ravaged villages in the UK have b...   \n",
       "3  The Environment Agency has issued 57 <b>flood<...   \n",
       "4  Despite some areas enduring their &#39;wettest...   \n",
       "\n",
       "                           date  \\\n",
       "0  2019-11-17T17:35:00.0000000Z   \n",
       "1  2019-11-17T18:35:00.0000000Z   \n",
       "2  2019-11-17T13:45:00.0000000Z   \n",
       "3  2019-11-17T16:38:00.0000000Z   \n",
       "4  2019-11-17T18:32:00.0000000Z   \n",
       "\n",
       "                                                link               source_url  \\\n",
       "0     https://www.bbc.co.uk/news/uk-england-50451817            www.bbc.co.uk   \n",
       "1  https://www.hulldailymail.co.uk/news/hull-east...  www.hulldailymail.co.uk   \n",
       "2  https://www.thesun.co.uk/news/10342583/uk-weat...         www.thesun.co.uk   \n",
       "3  https://www.express.co.uk/news/weather/1205629...        www.express.co.uk   \n",
       "4  https://www.mirror.co.uk/news/uk-news/uk-weath...         www.mirror.co.uk   \n",
       "\n",
       "          retrieval_timestamp         origin  \\\n",
       "0  2019-11-17 19:50:58.278878  bing_news_api   \n",
       "1  2019-11-17 19:50:58.278928  bing_news_api   \n",
       "2  2019-11-17 19:50:58.278953  bing_news_api   \n",
       "3  2019-11-17 19:50:58.279028  bing_news_api   \n",
       "4  2019-11-17 19:50:58.279047  bing_news_api   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  West Midlands flood warnings prompt ;remain vi...   \n",
       "1  New flood warnings issued with more homes at r...   \n",
       "2  UK weather forecast – More than 100 flood aler...   \n",
       "3  UK flood warning map: Flood chaos to continue ...   \n",
       "4  UK weather forecast: Flood chaos continues wit...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [west, midland, flood, warn, prompt, remain, v...   \n",
       "1  [new, flood, warn, issu, home, risk, environ, ...   \n",
       "2  [uk, weather, forecast, flood, alert, britain,...   \n",
       "3  [uk, flood, warn, map, flood, chao, continu, t...   \n",
       "4  [uk, weather, forecast, flood, chao, continu, ...   \n",
       "\n",
       "                                        corpus_tfidf  cluster     score  \n",
       "0  [(0, 0.10888666697011559), (1, 0.1157487091387...       22  0.320047  \n",
       "1  [(1, 0.237740646083191), (2, 0.118534432452920...       72  0.328762  \n",
       "2  [(2, 0.22914879635567142), (8, 0.1474814226459...       74  0.344483  \n",
       "3  [(1, 0.13183366830610094), (2, 0.1314611473326...       72  0.370900  \n",
       "4  [(8, 0.1193340118121436), (9, 0.25139370146632...       22  0.235525  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"working/disaster_clustered_lda.csv\")\n",
    "\n",
    "# Restore \"tokens\" from horrific string format\n",
    "# REF CHECK THIS FOR COMPATIBILITY WITH OTHER CLEANING STEPS\n",
    "df['tokens'] = df['tokens'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9,]\", \"\", x).split(\",\"))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherences = get_corpus_model_coherence(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c_v': 0.6540867957747499,\n",
       " 'c_npmi': 0.1013493367023562,\n",
       " 'u_mass': -3.23000860531844}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
