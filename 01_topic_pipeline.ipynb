{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Cleaning, Clustering & Summarization Pipelines\n",
    "\n",
    "### To do (technical)\n",
    "- Implement date windows on my corpus loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lib.helper import *\n",
    "import lib.embedding_models as reps\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be same path for all my PC's, it's where each scrape goes as a separate json file.\n",
    "storage_path = \"C:/Users/Martin/Dropbox/news_crow/scrape_results\"\n",
    "\n",
    "# \"bing\" is targeted news search corpus, \"RSS\" is from specific world and local news feeds.\n",
    "corpus_type = \"bing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.  Build Corpus\n",
    "\n",
    "The corpus is being scraped by the \"run_news_scrapes.py\" script (and windows task scheduler) every 12 hours, a bit past midday and a bit past midnight.\n",
    "\n",
    "The \"bing\" corpus are news titles and text extracts gotten from the bing news search API, using a few Home Office - related keywords.\n",
    "\n",
    "The \"RSS\" corpus is plugged directly into a number of RSS feeds for world news sites and local british news sites, with no filters for news story types or subjects applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, get a list of all the news dumps created so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus_loader(storage_path, corpus_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>origin</th>\n",
       "      <th>retrieval_timestamp</th>\n",
       "      <th>source_url</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-05T17:32:00.0000000Z</td>\n",
       "      <td>https://www.desmoinesregister.com/story/opinio...</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>2019-09-05 21:35:05.105002</td>\n",
       "      <td>www.desmoinesregister.com</td>\n",
       "      <td>&lt;b&gt;Immigration&lt;/b&gt; raids are as devastating to...</td>\n",
       "      <td>&lt;b&gt;Immigration&lt;/b&gt; raids are as devastating to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-05T20:06:00.0000000Z</td>\n",
       "      <td>https://www.philstar.com/the-freeman/cebu-news...</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>2019-09-05 21:35:05.105002</td>\n",
       "      <td>www.philstar.com</td>\n",
       "      <td>CEBU, Philippines — The Department of Justice ...</td>\n",
       "      <td>&lt;b&gt;Immigration&lt;/b&gt; told to monitor convicts: L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-05T17:21:00.0000000Z</td>\n",
       "      <td>https://www.irishtimes.com/news/crime-and-law/...</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>2019-09-05 21:35:05.106001</td>\n",
       "      <td>www.irishtimes.com</td>\n",
       "      <td>Three members of an organised crime gang were ...</td>\n",
       "      <td>Three people jailed for assisting illegal &lt;b&gt;i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-05T20:12:00.0000000Z</td>\n",
       "      <td>https://www.correctionsone.com/immigration-det...</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>2019-09-05 21:35:05.106001</td>\n",
       "      <td>www.correctionsone.com</td>\n",
       "      <td>NATCHEZ, Miss. — A privately run prison in Mis...</td>\n",
       "      <td>&lt;b&gt;Immigration&lt;/b&gt; agency sets new contract wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-05T19:27:00.0000000Z</td>\n",
       "      <td>https://www.nzherald.co.nz/nz/news/article.cfm...</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>2019-09-05 21:35:05.106001</td>\n",
       "      <td>www.nzherald.co.nz</td>\n",
       "      <td>A licensed &lt;b&gt;immigration&lt;/b&gt; adviser has been...</td>\n",
       "      <td>&lt;b&gt;Immigration&lt;/b&gt; adviser censured and fined ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  \\\n",
       "0  2019-09-05T17:32:00.0000000Z   \n",
       "1  2019-09-05T20:06:00.0000000Z   \n",
       "2  2019-09-05T17:21:00.0000000Z   \n",
       "3  2019-09-05T20:12:00.0000000Z   \n",
       "4  2019-09-05T19:27:00.0000000Z   \n",
       "\n",
       "                                                link         origin  \\\n",
       "0  https://www.desmoinesregister.com/story/opinio...  bing_news_api   \n",
       "1  https://www.philstar.com/the-freeman/cebu-news...  bing_news_api   \n",
       "2  https://www.irishtimes.com/news/crime-and-law/...  bing_news_api   \n",
       "3  https://www.correctionsone.com/immigration-det...  bing_news_api   \n",
       "4  https://www.nzherald.co.nz/nz/news/article.cfm...  bing_news_api   \n",
       "\n",
       "          retrieval_timestamp                 source_url  \\\n",
       "0  2019-09-05 21:35:05.105002  www.desmoinesregister.com   \n",
       "1  2019-09-05 21:35:05.105002           www.philstar.com   \n",
       "2  2019-09-05 21:35:05.106001         www.irishtimes.com   \n",
       "3  2019-09-05 21:35:05.106001     www.correctionsone.com   \n",
       "4  2019-09-05 21:35:05.106001         www.nzherald.co.nz   \n",
       "\n",
       "                                             summary  \\\n",
       "0  <b>Immigration</b> raids are as devastating to...   \n",
       "1  CEBU, Philippines — The Department of Justice ...   \n",
       "2  Three members of an organised crime gang were ...   \n",
       "3  NATCHEZ, Miss. — A privately run prison in Mis...   \n",
       "4  A licensed <b>immigration</b> adviser has been...   \n",
       "\n",
       "                                               title  \n",
       "0  <b>Immigration</b> raids are as devastating to...  \n",
       "1  <b>Immigration</b> told to monitor convicts: L...  \n",
       "2  Three people jailed for assisting illegal <b>i...  \n",
       "3  <b>Immigration</b> agency sets new contract wi...  \n",
       "4  <b>Immigration</b> adviser censured and fined ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4487, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean Text\n",
    "\n",
    "By default, I'm not going to clean out all punctuation because I think it informs the POS tagger to some degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['clean_text'] = corpus[['title', 'summary']].apply(lambda x: clean_text('.  '.join(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Immigration raids are as devastating to commun...\n",
       "1    Immigration told to monitor convicts: Lookout ...\n",
       "2    Three people jailed for assisting illegal immi...\n",
       "3    Immigration agency sets new contract with Miss...\n",
       "4    Immigration adviser censured and fined for far...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Build Text Model (Representation, eg; word2vec, entities list...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lib.embedding_models' from 'D:\\\\Martin\\\\Documents\\\\GitHub\\\\news_crow\\\\lib\\\\embedding_models.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows didn't play nicely with the vector datasets, Some obscure encoding problem (python in Conda\n",
    "# kept trying to decode using cp1252 regardless of whatever other options I specified!)\n",
    "# Solution; rewrite file and drop any characters the Windows encoder refuses to recognise.\n",
    "# I shouldn't loose too much info.\n",
    "#with open('./lib/InferSent/dataset/fastText/crawl-300d-2M.vec', \"r\", encoding=\"cp1252\", errors=\"ignore\") as infile:\n",
    "#    with open('./lib/InferSent/dataset/fastText/crawl-300d-2M_win.vec', \"wb\") as outfile:\n",
    "#        for line in infile:\n",
    "#            outfile.write(line.encode('cp1252'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8692(/9130) words with w2v vectors\n",
      "Vocab size : 8692\n"
     ]
    }
   ],
   "source": [
    "infersent = reps.InferSentModel(list(corpus['clean_text']),\n",
    "                                list(corpus['clean_text']),\n",
    "                                W2V_PATH = './lib/InferSent/dataset/fastText/crawl-300d-2M_win.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Martin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Whereas this worked first time!\n",
    "#glove = reps.GloveWordModel(list(corpus['clean_text']), list(corpus['clean_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = infersent.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
