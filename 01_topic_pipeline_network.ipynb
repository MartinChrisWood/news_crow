{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Cleaning, Clustering & Summarization Pipelines\n",
    "\n",
    "### To do (technical)\n",
    "- Implement date windows on my corpus loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lib.helper as helper\n",
    "import lib.embedding_models as reps\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Useful flatten function from Alex Martelli on https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Retrieve Corpus\n",
    "\n",
    "The corpus is being scraped by the \"run_news_scrapes.py\" script (and windows task scheduler) every 12 hours, a bit past midday and a bit past midnight.\n",
    "\n",
    "The \"bing\" corpus are news titles and text extracts gotten from the bing news search API, using a few Home Office - related keywords.\n",
    "\n",
    "The \"RSS\" corpus is plugged directly into a number of RSS feeds for world news sites and local british news sites, with no filters for news story types or subjects applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 485\n",
      "9.9 percent of files read.\n",
      "19.8 percent of files read.\n",
      "29.7 percent of files read.\n",
      "39.6 percent of files read.\n",
      "49.5 percent of files read.\n",
      "59.4 percent of files read.\n",
      "69.3 percent of files read.\n",
      "79.2 percent of files read.\n",
      "89.1 percent of files read.\n",
      "99.0 percent of files read.\n",
      "(60000, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>source_url</th>\n",
       "      <th>retrieval_timestamp</th>\n",
       "      <th>origin</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60192</th>\n",
       "      <td>598015</td>\n",
       "      <td>Rudy Giuliani sidekick Lev Parnas surfed porn ...</td>\n",
       "      <td>A phone that Lev Parnas turned over to the Hou...</td>\n",
       "      <td>Wed, 29 Jan 2020 23:00:37 GMT</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-79444...</td>\n",
       "      <td>https://www.dailymail.co.uk/news/articles.rss</td>\n",
       "      <td>2020-01-30 00:23:13.270518</td>\n",
       "      <td>rss_feed</td>\n",
       "      <td>Rudy Giuliani sidekick Lev Parnas surfed porn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60193</th>\n",
       "      <td>598016</td>\n",
       "      <td>Mallacoota family break down in tears on the T...</td>\n",
       "      <td>The Nelson-Parthenides family fled their home ...</td>\n",
       "      <td>Wed, 29 Jan 2020 22:51:28 GMT</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-79446...</td>\n",
       "      <td>https://www.dailymail.co.uk/news/articles.rss</td>\n",
       "      <td>2020-01-30 00:23:13.270527</td>\n",
       "      <td>rss_feed</td>\n",
       "      <td>Mallacoota family break down in tears on the T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60194</th>\n",
       "      <td>598017</td>\n",
       "      <td>Michigan man, 68, who served 24 of a 60-year p...</td>\n",
       "      <td>Michael Thompson, 68, is serving a 60-year pri...</td>\n",
       "      <td>Wed, 29 Jan 2020 22:36:57 GMT</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-79443...</td>\n",
       "      <td>https://www.dailymail.co.uk/news/articles.rss</td>\n",
       "      <td>2020-01-30 00:23:13.270535</td>\n",
       "      <td>rss_feed</td>\n",
       "      <td>Michigan man, 68, who served 24 of a 60-year p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60195</th>\n",
       "      <td>598018</td>\n",
       "      <td>Australian in Wuhan says his mother is terrifi...</td>\n",
       "      <td>Daniel Ou Yang is an Australian in the Chinese...</td>\n",
       "      <td>Wed, 29 Jan 2020 22:32:38 GMT</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-79448...</td>\n",
       "      <td>https://www.dailymail.co.uk/news/articles.rss</td>\n",
       "      <td>2020-01-30 00:23:13.270544</td>\n",
       "      <td>rss_feed</td>\n",
       "      <td>Australian in Wuhan says his mother is terrifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60196</th>\n",
       "      <td>598019</td>\n",
       "      <td>Five and ten cent coins to disappear within a ...</td>\n",
       "      <td>Silver five and 10 cent coins were introduced ...</td>\n",
       "      <td>Wed, 29 Jan 2020 22:32:27 GMT</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-79445...</td>\n",
       "      <td>https://www.dailymail.co.uk/news/articles.rss</td>\n",
       "      <td>2020-01-30 00:23:13.270552</td>\n",
       "      <td>rss_feed</td>\n",
       "      <td>Five and ten cent coins to disappear within a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                              title  \\\n",
       "node                                                               \n",
       "60192  598015  Rudy Giuliani sidekick Lev Parnas surfed porn ...   \n",
       "60193  598016  Mallacoota family break down in tears on the T...   \n",
       "60194  598017  Michigan man, 68, who served 24 of a 60-year p...   \n",
       "60195  598018  Australian in Wuhan says his mother is terrifi...   \n",
       "60196  598019  Five and ten cent coins to disappear within a ...   \n",
       "\n",
       "                                                 summary  \\\n",
       "node                                                       \n",
       "60192  A phone that Lev Parnas turned over to the Hou...   \n",
       "60193  The Nelson-Parthenides family fled their home ...   \n",
       "60194  Michael Thompson, 68, is serving a 60-year pri...   \n",
       "60195  Daniel Ou Yang is an Australian in the Chinese...   \n",
       "60196  Silver five and 10 cent coins were introduced ...   \n",
       "\n",
       "                                date  \\\n",
       "node                                   \n",
       "60192  Wed, 29 Jan 2020 23:00:37 GMT   \n",
       "60193  Wed, 29 Jan 2020 22:51:28 GMT   \n",
       "60194  Wed, 29 Jan 2020 22:36:57 GMT   \n",
       "60195  Wed, 29 Jan 2020 22:32:38 GMT   \n",
       "60196  Wed, 29 Jan 2020 22:32:27 GMT   \n",
       "\n",
       "                                                    link  \\\n",
       "node                                                       \n",
       "60192  https://www.dailymail.co.uk/news/article-79444...   \n",
       "60193  https://www.dailymail.co.uk/news/article-79446...   \n",
       "60194  https://www.dailymail.co.uk/news/article-79443...   \n",
       "60195  https://www.dailymail.co.uk/news/article-79448...   \n",
       "60196  https://www.dailymail.co.uk/news/article-79445...   \n",
       "\n",
       "                                          source_url  \\\n",
       "node                                                   \n",
       "60192  https://www.dailymail.co.uk/news/articles.rss   \n",
       "60193  https://www.dailymail.co.uk/news/articles.rss   \n",
       "60194  https://www.dailymail.co.uk/news/articles.rss   \n",
       "60195  https://www.dailymail.co.uk/news/articles.rss   \n",
       "60196  https://www.dailymail.co.uk/news/articles.rss   \n",
       "\n",
       "              retrieval_timestamp    origin  \\\n",
       "node                                          \n",
       "60192  2020-01-30 00:23:13.270518  rss_feed   \n",
       "60193  2020-01-30 00:23:13.270527  rss_feed   \n",
       "60194  2020-01-30 00:23:13.270535  rss_feed   \n",
       "60195  2020-01-30 00:23:13.270544  rss_feed   \n",
       "60196  2020-01-30 00:23:13.270552  rss_feed   \n",
       "\n",
       "                                              clean_text  \n",
       "node                                                      \n",
       "60192  Rudy Giuliani sidekick Lev Parnas surfed porn ...  \n",
       "60193  Mallacoota family break down in tears on the T...  \n",
       "60194  Michigan man, 68, who served 24 of a 60-year p...  \n",
       "60195  Australian in Wuhan says his mother is terrifi...  \n",
       "60196  Five and ten cent coins to disappear within a ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be same path for all my PC's, it's where each scrape goes as a separate json file.\n",
    "storage_path = \"D:/Dropbox/news_crow/scrape_results\"\n",
    "\n",
    "# \"bing\" is targeted news search corpus, \"RSS\" is from specific world and local news feeds.\n",
    "corpus_type = \"RSS\"\n",
    "\n",
    "# There's a helper function to go find and drag out the various JSON files created by the scrapers.\n",
    "corpus = helper.load_clean_corpus(storage_path, corpus_type)\n",
    "\n",
    "# Make sure after cleaning etc it's indexed from 0\n",
    "corpus.reset_index(inplace=True)\n",
    "corpus.index.name = \"node\"\n",
    "\n",
    "# Subset to latest half to see if it'll run in memory\n",
    "corpus = corpus.iloc[-60000:,]\n",
    "\n",
    "# See how it turned out\n",
    "print(corpus.shape)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use Detected Nouns to create a Graph Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ambulance</th>\n",
       "      <th>seeapos</th>\n",
       "      <th>Maple</th>\n",
       "      <th>Shore</th>\n",
       "      <th>talkapos</th>\n",
       "      <th>Antonio_Guterres</th>\n",
       "      <th>Beers</th>\n",
       "      <th>Video</th>\n",
       "      <th>Wuhan_Hubei</th>\n",
       "      <th>A20</th>\n",
       "      <th>...</th>\n",
       "      <th>Schumerapos;s</th>\n",
       "      <th>apos;disturbing</th>\n",
       "      <th>Champs</th>\n",
       "      <th>Blair</th>\n",
       "      <th>Inhumane</th>\n",
       "      <th>FTSE_Britain</th>\n",
       "      <th>Hindley</th>\n",
       "      <th>Democrat_Joe</th>\n",
       "      <th>Teague</th>\n",
       "      <th>Telarah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rudy Giuliani sidekick Lev Parnas surfed porn and hook-up websites, phone he turned over reveals. A phone that Lev Parnas turned over to the House containing voluminous materials about the Ukraine affair also includes searches of porn and hookup sites, according to a report.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mallacoota family break down in tears on the Today Show after they're given a car after bushfire. The Nelson-Parthenides family fled their home in Mallacoota on December 2 - just days before the skies turned an eerie red as a ferocious blaze tore through the region.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan man, 68, who served 24 of a 60-year prison sentence for selling pot, pleads for clemency. Michael Thompson, 68, is serving a 60-year prison sentence in Michigan for selling marijuana to an informant on Wednesday asked for a clemency for a second time in the hopes of an earlier release</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian in Wuhan says his mother is terrified he may be quarantined over coronavirus. Daniel Ou Yang is an Australian in the Chinese city of Wuhan and fearful of his uncertain future.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five and ten cent coins to disappear within a decade - Australian Mint demand plummet. Silver five and 10 cent coins were introduced in Australia in 166, and 46million of them were minted in 2006.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Ambulance  seeapos  Maple  \\\n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...          0        0      0   \n",
       "Mallacoota family break down in tears on the To...          0        0      0   \n",
       "Michigan man, 68, who served 24 of a 60-year pr...          0        0      0   \n",
       "Australian in Wuhan says his mother is terrifie...          0        0      0   \n",
       "Five and ten cent coins to disappear within a d...          0        0      0   \n",
       "\n",
       "                                                    Shore  talkapos  \\\n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...      0         0   \n",
       "Mallacoota family break down in tears on the To...      0         0   \n",
       "Michigan man, 68, who served 24 of a 60-year pr...      0         0   \n",
       "Australian in Wuhan says his mother is terrifie...      0         0   \n",
       "Five and ten cent coins to disappear within a d...      0         0   \n",
       "\n",
       "                                                    Antonio_Guterres  Beers  \\\n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...                 0      0   \n",
       "Mallacoota family break down in tears on the To...                 0      0   \n",
       "Michigan man, 68, who served 24 of a 60-year pr...                 0      0   \n",
       "Australian in Wuhan says his mother is terrifie...                 0      0   \n",
       "Five and ten cent coins to disappear within a d...                 0      0   \n",
       "\n",
       "                                                    Video  Wuhan_Hubei  A20  \\\n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...      0            0    0   \n",
       "Mallacoota family break down in tears on the To...      0            0    0   \n",
       "Michigan man, 68, who served 24 of a 60-year pr...      0            0    0   \n",
       "Australian in Wuhan says his mother is terrifie...      0            0    0   \n",
       "Five and ten cent coins to disappear within a d...      0            0    0   \n",
       "\n",
       "                                                    ...  Schumerapos;s  \\\n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...  ...              0   \n",
       "Mallacoota family break down in tears on the To...  ...              0   \n",
       "Michigan man, 68, who served 24 of a 60-year pr...  ...              0   \n",
       "Australian in Wuhan says his mother is terrifie...  ...              0   \n",
       "Five and ten cent coins to disappear within a d...  ...              0   \n",
       "\n",
       "                                                    apos;disturbing  Champs  \\\n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...                0       0   \n",
       "Mallacoota family break down in tears on the To...                0       0   \n",
       "Michigan man, 68, who served 24 of a 60-year pr...                0       0   \n",
       "Australian in Wuhan says his mother is terrifie...                0       0   \n",
       "Five and ten cent coins to disappear within a d...                0       0   \n",
       "\n",
       "                                                    Blair  Inhumane  \\\n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...      0         0   \n",
       "Mallacoota family break down in tears on the To...      0         0   \n",
       "Michigan man, 68, who served 24 of a 60-year pr...      0         0   \n",
       "Australian in Wuhan says his mother is terrifie...      0         0   \n",
       "Five and ten cent coins to disappear within a d...      0         0   \n",
       "\n",
       "                                                    FTSE_Britain  Hindley  \\\n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...             0        0   \n",
       "Mallacoota family break down in tears on the To...             0        0   \n",
       "Michigan man, 68, who served 24 of a 60-year pr...             0        0   \n",
       "Australian in Wuhan says his mother is terrifie...             0        0   \n",
       "Five and ten cent coins to disappear within a d...             0        0   \n",
       "\n",
       "                                                    Democrat_Joe  Teague  \\\n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...             0       0   \n",
       "Mallacoota family break down in tears on the To...             0       0   \n",
       "Michigan man, 68, who served 24 of a 60-year pr...             0       0   \n",
       "Australian in Wuhan says his mother is terrifie...             0       0   \n",
       "Five and ten cent coins to disappear within a d...             0       0   \n",
       "\n",
       "                                                    Telarah  \n",
       "Rudy Giuliani sidekick Lev Parnas surfed porn a...        0  \n",
       "Mallacoota family break down in tears on the To...        0  \n",
       "Michigan man, 68, who served 24 of a 60-year pr...        0  \n",
       "Australian in Wuhan says his mother is terrifie...        0  \n",
       "Five and ten cent coins to disappear within a d...        0  \n",
       "\n",
       "[5 rows x 40493 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the text representation\n",
    "model = reps.NounAdjacencyModel(list(corpus['clean_text']), list(corpus['clean_text']))\n",
    "\n",
    "# Tabulate for convenience\n",
    "nouns_df = model.table.copy()\n",
    "nouns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop any noun/noun phrase containing one of the search terms, then create an adjacency matrix\n",
    "\n",
    "#### Drop any noun/phrase occuring too infrequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive the set of search terms used for Bing, so we can remove them before\n",
    "# clustering.\n",
    "with open(\"D:/Dropbox/news_crow/scrape_settings.json\", \"r\") as f:\n",
    "    scrape_config = json.load(f)\n",
    "\n",
    "search_terms = scrape_config['disaster_search_list']\n",
    "search_terms = re.sub(r\"[^0-9A-Za-z ]\", \"\", \" \".join(search_terms)).lower().split()\n",
    "search_terms = set(search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Get X most common nouns WHY NOT USE TFIDF HERE?\n",
    "nouns_to_keep = list(nouns_df.\\\n",
    "                    sum(axis=0).\\\n",
    "                    sort_values(ascending=False).\\\n",
    "                    index)\n",
    "\n",
    "# Cut out any nouns containing the original search terms\n",
    "#nouns_to_keep = [noun for noun in nouns_to_keep if sum([term in noun for term in search_terms]) == 0]\n",
    "\n",
    "# Keep only most common\n",
    "nouns_to_keep = nouns_to_keep[:2000]\n",
    "\n",
    "# Subset nouns dataframe\n",
    "nouns_df = nouns_df[nouns_to_keep]\n",
    "\n",
    "print(nouns_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.asarray(nouns_df)\n",
    "adjacency = np.dot(embeddings, embeddings.T)\n",
    "print(np.max(adjacency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the \"lower\" limit is 1, the graph has so many edges it eats ALL the memory of my desktop, even\n",
    "# with just 500-ish stories to process.\n",
    "upper = 100\n",
    "lower = 3\n",
    "G = nx.Graph()\n",
    "rows, cols = np.where((upper >= adjacency) & (adjacency >= lower))\n",
    "weights = [float(adjacency[rows[i], cols[i]]) for i in range(len(rows))]\n",
    "edges = zip(rows.tolist(), cols.tolist(), weights)\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# Simplify; remove self-edges - not sure if needed?\n",
    "G.remove_edges_from(nx.selfloop_edges(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12596 to beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c.  Try CDLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdlib\n",
    "from cdlib import algorithms\n",
    "from cdlib import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple (flat) clustering\n",
    "lp_coms = algorithms.label_propagation(G)\n",
    "\n",
    "# Traditional (easy) community detection\n",
    "louvain_coms = algorithms.louvain(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This result implies that the two methods have come to very similar conclusions...\n",
    "# This function apparently isn't defined for overlapping communities\n",
    "evaluation.normalized_mutual_information(lp_coms, louvain_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dict of node-to-cluster lookup\n",
    "community_lookup = {}\n",
    "for comm_index, members in enumerate(louvain_coms.communities):\n",
    "    for member in members:\n",
    "        community_lookup[member] = comm_index\n",
    "\n",
    "# Add cluster to DF.  If node not in cluster, assign -1 (outlier)\n",
    "corpus['node'] = corpus.index\n",
    "corpus['cluster'] = corpus['node'].apply(lambda x: community_lookup.get(x, -1))\n",
    "corpus[['clean_text', 'cluster']].head(10)\n",
    "\n",
    "# If cluster is smaller than minimum limit, designate as outlier\n",
    "cs_lookup = corpus['cluster'].value_counts().to_dict()\n",
    "corpus['cluster'] = corpus['cluster'].apply(lambda x: -1 if (cs_lookup[x] < 5) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentage are now classed as outliers?\n",
    "100.0 * sum(corpus['cluster']==-1) / corpus.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique clusters after all this?  (minus one for outliers)\n",
    "len(pd.unique(corpus['cluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv(\"working/RSS_clustered_louvain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigclam_coms.communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigclam_coms.average_internal_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigclam_coms.newman_girvan_modularity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Create (overlapping) clusters using Maximal Cliques\n",
    "Idea from the docs, explanation at https://en.wikipedia.org/wiki/Clique_(graph_theory)\n",
    "Expanded using k-clique-communities REF FIND PAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(nx.algorithms.community.kclique.k_clique_communities(G, 4))\n",
    "cliques = [(len(x), x) for x in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques_df = pd.DataFrame({\"nodes_list\": [x[1] for x in cliques],\n",
    "                           \"clique_size\": [x[0] for x in cliques]}).\\\n",
    "                    sort_values(\"clique_size\", ascending=False).\\\n",
    "                    reset_index()\n",
    "\n",
    "cliques_df = cliques_df[(cliques_df['clique_size'] >= 3) & (cliques_df['clique_size'] <=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cliques_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliqued = set(flatten(list(cliques_df['nodes_list'])))\n",
    "len(cliqued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the cliques DF into long format\n",
    "flattened = {\"cluster_index\":[], \"node\":[]}\n",
    "\n",
    "for index, row in cliques_df.iterrows():\n",
    "    for node in row[\"nodes_list\"]:\n",
    "        flattened[\"cluster_index\"].append(index)\n",
    "        flattened[\"node\"].append(node)\n",
    "        \n",
    "\n",
    "partition_df = pd.DataFrame(flattened)\n",
    "\n",
    "# Create a single string variable (\";\" separated) to record all clusters/cliques a single record belongs in\n",
    "partition_df[\"cluster\"] = partition_df.\\\n",
    "                          groupby(\"node\")[\"cluster_index\"].\\\n",
    "                          transform(lambda x: \";\".join([str(i) for i in x if type(i)==int]))\n",
    "\n",
    "# Clean up, set index of this and corpus so the two DF's can be joined with little effort\n",
    "partition_df = partition_df[[\"node\", \"cluster\"]].\\\n",
    "               drop_duplicates([\"node\", \"cluster\"], keep=\"first\").\\\n",
    "               set_index(\"node\")\n",
    "\n",
    "corpus.drop([\"cluster\", \"node\"], axis=1).join(partition_df).\\\n",
    "       to_csv(\"working/RSS_clustered_cliques.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below attempts overlapping community detection but can only run on connected graphs, think this is an implicit restriction of the algorithm logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all connected components (will become less of an issue as graph size increases)\n",
    "ccs = [(len(x), x) for x in nx.connected_components(G)]\n",
    "\n",
    "# Sort by size (largest first)\n",
    "ccs.sort(key = lambda x: x[0], reverse=True)\n",
    "\n",
    "# Extract largest connected sub-graph\n",
    "connected_sub = G.subgraph(ccs[0][1])\n",
    "\n",
    "# re-index nodes from zero to maintain compatibility with CDLIB (sub-dependency, Karate)\n",
    "# Will need to reverse this indexing when matching assigned clusters back to data\n",
    "node_relabel_dict = {val: i for i, val in enumerate(list(connected_sub.nodes))}\n",
    "\n",
    "connected_sub = nx.relabel_nodes(connected_sub, node_relabel_dict)\n",
    "\n",
    "# Fire algo!\n",
    "bigclam_coms = algorithms.big_clam(connected_sub)\n",
    "#leiden_coms = algorithms.leiden(connected_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigclam_coms.communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dict of node-to-cluster lookup\n",
    "community_lookup = {}\n",
    "for comm_index, members in enumerate(bigclam_coms.communities):\n",
    "    for member in members:\n",
    "        community_lookup[member] = community_lookup.get(member, []) + [comm_index]\n",
    "\n",
    "# Add cluster to DF.  If node not in cluster, assign -1 (outlier)\n",
    "corpus['node'] = corpus.index\n",
    "corpus['cluster'] = corpus['node'].apply(lambda x: community_lookup.get(x, [-1]))\n",
    "corpus[['clean_text', 'cluster']].head(10)\n",
    "\n",
    "# If cluster is smaller than minimum limit, designate as outlier\n",
    "cs_lookup = corpus['cluster'].value_counts().to_dict()\n",
    "corpus['cluster'] = corpus['cluster'].apply(lambda x: -1 if (cs_lookup[x] < 5) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentage are now classed as outliers?\n",
    "100.0 * sum(corpus['cluster']==-1) / corpus.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique clusters after all this?  (minus one for outliers)\n",
    "len(pd.unique(corpus['cluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv(\"working/disaster_clustered_bigclam.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
