{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Cleaning, Clustering & Summarization Pipelines\n",
    "\n",
    "### To do (technical)\n",
    "- Implement date windows on my corpus loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lib.helper as helper\n",
    "import lib.embedding_models as reps\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Retrieve Corpus\n",
    "\n",
    "The corpus is being scraped by the \"run_news_scrapes.py\" script (and windows task scheduler) every 12 hours, a bit past midday and a bit past midnight.\n",
    "\n",
    "The \"bing\" corpus are news titles and text extracts gotten from the bing news search API, using a few Home Office - related keywords.\n",
    "\n",
    "The \"RSS\" corpus is plugged directly into a number of RSS feeds for world news sites and local british news sites, with no filters for news story types or subjects applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 155\n",
      "9.7 percent of files read.\n",
      "19.4 percent of files read.\n",
      "29.0 percent of files read.\n",
      "38.7 percent of files read.\n",
      "48.4 percent of files read.\n",
      "58.1 percent of files read.\n",
      "67.7 percent of files read.\n",
      "77.4 percent of files read.\n",
      "87.1 percent of files read.\n",
      "96.8 percent of files read.\n",
      "(12592, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>source_url</th>\n",
       "      <th>retrieval_timestamp</th>\n",
       "      <th>origin</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>West Midlands &lt;b&gt;flood&lt;/b&gt; warnings prompt &amp;#3...</td>\n",
       "      <td>Residents have been warned to &amp;quot;remain vig...</td>\n",
       "      <td>2019-11-17T17:35:00.0000000Z</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-50451817</td>\n",
       "      <td>www.bbc.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.278878</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>West Midlands flood warnings prompt ;remain vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>New &lt;b&gt;flood&lt;/b&gt; warnings issued with more hom...</td>\n",
       "      <td>The Environment Agency has a number of &lt;b&gt;floo...</td>\n",
       "      <td>2019-11-17T18:35:00.0000000Z</td>\n",
       "      <td>https://www.hulldailymail.co.uk/news/hull-east...</td>\n",
       "      <td>www.hulldailymail.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.278928</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>New flood warnings issued with more homes at r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>UK weather forecast – More than 100 &lt;b&gt;flood&lt;/...</td>\n",
       "      <td>&lt;b&gt;FLOOD&lt;/b&gt;-ravaged villages in the UK have b...</td>\n",
       "      <td>2019-11-17T13:45:00.0000000Z</td>\n",
       "      <td>https://www.thesun.co.uk/news/10342583/uk-weat...</td>\n",
       "      <td>www.thesun.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.278953</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>UK weather forecast – More than 100 flood aler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>UK &lt;b&gt;flood&lt;/b&gt; warning map: &lt;b&gt;Flood&lt;/b&gt; chao...</td>\n",
       "      <td>The Environment Agency has issued 57 &lt;b&gt;flood&lt;...</td>\n",
       "      <td>2019-11-17T16:38:00.0000000Z</td>\n",
       "      <td>https://www.express.co.uk/news/weather/1205629...</td>\n",
       "      <td>www.express.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.279028</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>UK flood warning map: Flood chaos to continue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>UK weather forecast: &lt;b&gt;Flood&lt;/b&gt; chaos contin...</td>\n",
       "      <td>Despite some areas enduring their &amp;#39;wettest...</td>\n",
       "      <td>2019-11-17T18:32:00.0000000Z</td>\n",
       "      <td>https://www.mirror.co.uk/news/uk-news/uk-weath...</td>\n",
       "      <td>www.mirror.co.uk</td>\n",
       "      <td>2019-11-17 19:50:58.279047</td>\n",
       "      <td>bing_news_api</td>\n",
       "      <td>UK weather forecast: Flood chaos continues wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                              title  \\\n",
       "node                                                             \n",
       "0         0  West Midlands <b>flood</b> warnings prompt &#3...   \n",
       "1         1  New <b>flood</b> warnings issued with more hom...   \n",
       "2         2  UK weather forecast – More than 100 <b>flood</...   \n",
       "3         5  UK <b>flood</b> warning map: <b>Flood</b> chao...   \n",
       "4         6  UK weather forecast: <b>Flood</b> chaos contin...   \n",
       "\n",
       "                                                summary  \\\n",
       "node                                                      \n",
       "0     Residents have been warned to &quot;remain vig...   \n",
       "1     The Environment Agency has a number of <b>floo...   \n",
       "2     <b>FLOOD</b>-ravaged villages in the UK have b...   \n",
       "3     The Environment Agency has issued 57 <b>flood<...   \n",
       "4     Despite some areas enduring their &#39;wettest...   \n",
       "\n",
       "                              date  \\\n",
       "node                                 \n",
       "0     2019-11-17T17:35:00.0000000Z   \n",
       "1     2019-11-17T18:35:00.0000000Z   \n",
       "2     2019-11-17T13:45:00.0000000Z   \n",
       "3     2019-11-17T16:38:00.0000000Z   \n",
       "4     2019-11-17T18:32:00.0000000Z   \n",
       "\n",
       "                                                   link  \\\n",
       "node                                                      \n",
       "0        https://www.bbc.co.uk/news/uk-england-50451817   \n",
       "1     https://www.hulldailymail.co.uk/news/hull-east...   \n",
       "2     https://www.thesun.co.uk/news/10342583/uk-weat...   \n",
       "3     https://www.express.co.uk/news/weather/1205629...   \n",
       "4     https://www.mirror.co.uk/news/uk-news/uk-weath...   \n",
       "\n",
       "                   source_url         retrieval_timestamp         origin  \\\n",
       "node                                                                       \n",
       "0               www.bbc.co.uk  2019-11-17 19:50:58.278878  bing_news_api   \n",
       "1     www.hulldailymail.co.uk  2019-11-17 19:50:58.278928  bing_news_api   \n",
       "2            www.thesun.co.uk  2019-11-17 19:50:58.278953  bing_news_api   \n",
       "3           www.express.co.uk  2019-11-17 19:50:58.279028  bing_news_api   \n",
       "4            www.mirror.co.uk  2019-11-17 19:50:58.279047  bing_news_api   \n",
       "\n",
       "                                             clean_text  \n",
       "node                                                     \n",
       "0     West Midlands flood warnings prompt ;remain vi...  \n",
       "1     New flood warnings issued with more homes at r...  \n",
       "2     UK weather forecast – More than 100 flood aler...  \n",
       "3     UK flood warning map: Flood chaos to continue ...  \n",
       "4     UK weather forecast: Flood chaos continues wit...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be same path for all my PC's, it's where each scrape goes as a separate json file.\n",
    "storage_path = \"D:/Dropbox/news_crow/scrape_results\"\n",
    "\n",
    "# \"bing\" is targeted news search corpus, \"RSS\" is from specific world and local news feeds.\n",
    "corpus_type = \"disaster\"\n",
    "\n",
    "# There's a helper function to go find and drag out the various JSON files created by the scrapers.\n",
    "corpus = helper.load_clean_corpus(storage_path, corpus_type)\n",
    "\n",
    "# Make sure after cleaning etc it's indexed from 0\n",
    "corpus.reset_index(inplace=True)\n",
    "corpus.index.name = \"node\"\n",
    "\n",
    "# See how it turned out\n",
    "print(corpus.shape)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use Detected Nouns to create a Graph Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive the set of search terms used for Bing, so we can remove them before\n",
    "# clustering.\n",
    "with open(\"D:/Dropbox/news_crow/scrape_settings.json\", \"r\") as f:\n",
    "    scrape_config = json.load(f)\n",
    "\n",
    "search_terms = scrape_config['disaster_search_list']\n",
    "search_terms = re.sub(r\"[^0-9A-Za-z ]\", \"\", \" \".join(search_terms)).lower().split()\n",
    "search_terms = set(search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protection</th>\n",
       "      <th>CONSPIRACY</th>\n",
       "      <th>Duffin</th>\n",
       "      <th>Rugby</th>\n",
       "      <th>McLennan</th>\n",
       "      <th>evening;s</th>\n",
       "      <th>Hampstead</th>\n",
       "      <th>Ethiopia_Somalia</th>\n",
       "      <th>quot;immense</th>\n",
       "      <th>FNN</th>\n",
       "      <th>...</th>\n",
       "      <th>Rutter</th>\n",
       "      <th>Setoo;s</th>\n",
       "      <th>Chaplain</th>\n",
       "      <th>Drones</th>\n",
       "      <th>Lingus</th>\n",
       "      <th>Barnwood</th>\n",
       "      <th>Churston</th>\n",
       "      <th>coronavirus_UAE</th>\n",
       "      <th>Arlo</th>\n",
       "      <th>Gunn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>West Midlands flood warnings prompt ;remain vigilant; alert. Residents have been warned to quot;remain vigilantquot; as up to 20 flood warnings are in place in the West Midlands with more rain forecast. There are 1 warnings affecting Worcestershire, along the River Severn, Avon and Teme, and six in Shropshire. Flood defences were put up in Ironbridge on Saturday evening. The Environment Agency (EA) said river ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>New flood warnings issued with more homes at risk. The Environment Agency has a number of flood alerts and warnings in place More residents are being told that floodwater could enter their homes as new red warnings are put in place. The Environment Agency has updated the flood risk for Hull and East Yorkshire this afternoon with four red flood warnings now in force. A red warning indicates that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>UK weather forecast – More than 100 flood alerts across Britain as villages are cut off for days and more storms hit. FLOOD-ravaged villages in the UK have been cut off for days as Atlantic storms threaten to unleash another deluge early next week. Swathes of Britain that were left devastated by torrential downpours will face yet more floods - with more than 100 alerts in place. It comes amid predictions bitterly cold weather will largely hold out for the rest ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>UK flood warning map: Flood chaos to continue - Where is under threat of flooding?. The Environment Agency has issued 57 flood warnings at the time of writing, meaning flooding is expected and immediate action is required. There are also 0 flood alerts in place across the country, warning flooding is possible and to be prepared, READ MORE: Snow maps latest forecast: Arctic blast to hit UK with snow and sleet To see a full ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>UK weather forecast: Flood chaos continues with -5C freeze to follow ;wettest autumn;. Despite some areas enduring their ;wettest ever autumns;, much-needed relief from heavy rainfall has been forecast for flood-hit areas in the coming days</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16067 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    protection  CONSPIRACY  \\\n",
       "West Midlands flood warnings prompt ;remain vig...           0           0   \n",
       "New flood warnings issued with more homes at ri...           0           0   \n",
       "UK weather forecast – More than 100 flood alert...           0           0   \n",
       "UK flood warning map: Flood chaos to continue -...           0           0   \n",
       "UK weather forecast: Flood chaos continues with...           0           0   \n",
       "\n",
       "                                                    Duffin  Rugby  McLennan  \\\n",
       "West Midlands flood warnings prompt ;remain vig...       0      0         0   \n",
       "New flood warnings issued with more homes at ri...       0      0         0   \n",
       "UK weather forecast – More than 100 flood alert...       0      0         0   \n",
       "UK flood warning map: Flood chaos to continue -...       0      0         0   \n",
       "UK weather forecast: Flood chaos continues with...       0      0         0   \n",
       "\n",
       "                                                    evening;s  Hampstead  \\\n",
       "West Midlands flood warnings prompt ;remain vig...          0          0   \n",
       "New flood warnings issued with more homes at ri...          0          0   \n",
       "UK weather forecast – More than 100 flood alert...          0          0   \n",
       "UK flood warning map: Flood chaos to continue -...          0          0   \n",
       "UK weather forecast: Flood chaos continues with...          0          0   \n",
       "\n",
       "                                                    Ethiopia_Somalia  \\\n",
       "West Midlands flood warnings prompt ;remain vig...                 0   \n",
       "New flood warnings issued with more homes at ri...                 0   \n",
       "UK weather forecast – More than 100 flood alert...                 0   \n",
       "UK flood warning map: Flood chaos to continue -...                 0   \n",
       "UK weather forecast: Flood chaos continues with...                 0   \n",
       "\n",
       "                                                    quot;immense  FNN  ...  \\\n",
       "West Midlands flood warnings prompt ;remain vig...             0    0  ...   \n",
       "New flood warnings issued with more homes at ri...             0    0  ...   \n",
       "UK weather forecast – More than 100 flood alert...             0    0  ...   \n",
       "UK flood warning map: Flood chaos to continue -...             0    0  ...   \n",
       "UK weather forecast: Flood chaos continues with...             0    0  ...   \n",
       "\n",
       "                                                    Rutter  Setoo;s  Chaplain  \\\n",
       "West Midlands flood warnings prompt ;remain vig...       0        0         0   \n",
       "New flood warnings issued with more homes at ri...       0        0         0   \n",
       "UK weather forecast – More than 100 flood alert...       0        0         0   \n",
       "UK flood warning map: Flood chaos to continue -...       0        0         0   \n",
       "UK weather forecast: Flood chaos continues with...       0        0         0   \n",
       "\n",
       "                                                    Drones  Lingus  Barnwood  \\\n",
       "West Midlands flood warnings prompt ;remain vig...       0       0         0   \n",
       "New flood warnings issued with more homes at ri...       0       0         0   \n",
       "UK weather forecast – More than 100 flood alert...       0       0         0   \n",
       "UK flood warning map: Flood chaos to continue -...       0       0         0   \n",
       "UK weather forecast: Flood chaos continues with...       0       0         0   \n",
       "\n",
       "                                                    Churston  coronavirus_UAE  \\\n",
       "West Midlands flood warnings prompt ;remain vig...         0                0   \n",
       "New flood warnings issued with more homes at ri...         0                0   \n",
       "UK weather forecast – More than 100 flood alert...         0                0   \n",
       "UK flood warning map: Flood chaos to continue -...         0                0   \n",
       "UK weather forecast: Flood chaos continues with...         0                0   \n",
       "\n",
       "                                                    Arlo  Gunn  \n",
       "West Midlands flood warnings prompt ;remain vig...     0     0  \n",
       "New flood warnings issued with more homes at ri...     0     0  \n",
       "UK weather forecast – More than 100 flood alert...     0     0  \n",
       "UK flood warning map: Flood chaos to continue -...     0     0  \n",
       "UK weather forecast: Flood chaos continues with...     0     0  \n",
       "\n",
       "[5 rows x 16067 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the text representation\n",
    "model = reps.NounAdjacencyModel(list(corpus['clean_text']), list(corpus['clean_text']))\n",
    "\n",
    "# Tabulate for convenience\n",
    "nouns_df = model.table.copy()\n",
    "nouns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop any noun/noun phrase containing one of the search terms, then create an adjacency matrix\n",
    "\n",
    "#### Drop any noun/phrase occuring too infrequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12592, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Get X most common nouns\n",
    "nouns_to_keep = list(nouns_df.\\\n",
    "                    sum(axis=0).\\\n",
    "                    sort_values(ascending=False).\\\n",
    "                    index)\n",
    "\n",
    "# Cut out any nouns containing the original search terms\n",
    "nouns_to_keep = [noun for noun in nouns_to_keep if sum([term in noun for term in search_terms]) == 0]\n",
    "\n",
    "# Keep only most common\n",
    "nouns_to_keep = nouns_to_keep[:2000]\n",
    "\n",
    "# Subset nouns dataframe\n",
    "nouns_df = nouns_df[nouns_to_keep]\n",
    "\n",
    "print(nouns_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.asarray(nouns_df)\n",
    "adjacency = np.dot(embeddings, embeddings.T)\n",
    "print(np.max(adjacency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the \"lower\" limit is 1, the graph has so many edges it eats ALL the memory of my desktop, even\n",
    "# with just 500-ish stories to process.\n",
    "upper = 100\n",
    "lower = 3\n",
    "G = nx.Graph()\n",
    "rows, cols = np.where((upper >= adjacency) & (adjacency >= lower))\n",
    "weights = [float(adjacency[rows[i], cols[i]]) for i in range(len(rows))]\n",
    "edges = zip(rows.tolist(), cols.tolist(), weights)\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# Simplify; remove self-edges - not sure if needed?\n",
    "G.remove_edges_from(nx.selfloop_edges(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Create (overlapping) clusters using Maximal Cliques\n",
    "Idea from the docs, explanation at https://en.wikipedia.org/wiki/Clique_(graph_theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques = []\n",
    "for x in nx.find_cliques(G):\n",
    "    x.sort()\n",
    "    cliques.append((len(x), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques_df = pd.DataFrame({\"nodes_list\": [x[1] for x in cliques],\n",
    "                           \"clique_size\": [x[0] for x in cliques]}).\\\n",
    "                    sort_values(\"clique_size\", ascending=False).\\\n",
    "                    reset_index()\n",
    "\n",
    "cliques_df = cliques_df[(cliques_df['clique_size'] >= 5) & (cliques_df['clique_size'] <=30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cliques_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful flatten function from Alex Martelli on https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliqued = set(flatten(list(cliques_df['nodes_list'])))\n",
    "len(cliqued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the cliques DF into long format\n",
    "flattened = {\"cluster_index\":[], \"node\":[]}\n",
    "\n",
    "for index, row in cliques_df.iterrows():\n",
    "    for node in row[\"nodes_list\"]:\n",
    "        flattened[\"cluster_index\"].append(index)\n",
    "        flattened[\"node\"].append(node)\n",
    "        \n",
    "\n",
    "partition_df = pd.DataFrame(flattened)\n",
    "\n",
    "# Create a single string variable (\";\" separated) to record all clusters/cliques a single record belongs in\n",
    "partition_df[\"cluster\"] = partition_df.\\\n",
    "                          groupby(\"node\")[\"cluster_index\"].\\\n",
    "                          transform(lambda x: \";\".join([str(i) for i in x if type(i)==int]))\n",
    "\n",
    "# Clean up, set index of this and corpus so the two DF's can be joined with little effort\n",
    "partition_df = partition_df[[\"node\", \"cluster\"]].\\\n",
    "               drop_duplicates([\"node\", \"cluster\"], keep=\"first\").\\\n",
    "               set_index(\"node\")\n",
    "\n",
    "corpus.join(partition_df).\\\n",
    "       to_csv(\"working/corpus_clustered_cliques.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node in cliques_df.iloc[0]['nodes_list']:\n",
    "    print(corpus.iloc[node]['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node in cliques_df.iloc[1]['nodes_list']:\n",
    "    print(corpus.iloc[node]['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node in cliques_df.iloc[2]['nodes_list']:\n",
    "    print(corpus.iloc[node]['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create (flat) clusters using the Community Detection Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community import best_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Louvain Community Detection\n",
    "# The keys are nodes, the values are the partitions they belong to\n",
    "partition = best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append partition data to DF, save to file\n",
    "partition_df = pd.DataFrame.\\\n",
    "               from_dict(partition, orient=\"index\").\\\n",
    "               rename({0: \"cluster\"}, axis=1)\n",
    "\n",
    "partition_df[\"cluster\"] = partition_df[\"cluster\"].apply(lambda x: str(int(x)))\n",
    "\n",
    "partition_df.index.name = \"node\"\n",
    "\n",
    "corpus.join(partition_df).\\\n",
    "       to_csv(\"working/corpus_clustered_louvain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through and get a list of partitions and their nodes\n",
    "partition_contents = {}\n",
    "for key in partition.keys():\n",
    "    partition_contents[partition[key]] = partition_contents.get(partition[key], []) + [key]\n",
    "\n",
    "# Drop partitions that are too small\n",
    "for key in list(partition_contents.keys()):\n",
    "    if len(partition_contents[key]) < 3:\n",
    "        partition_contents.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how big our \"clusters\" are, and how many there are total after removing the tiny ones\n",
    "partition_lengths = {key:len(value) for key, value in partition_contents.items()}\n",
    "print(partition_lengths, sum(partition_lengths.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node in partition_contents[1][:10]:\n",
    "    print(corpus.iloc[node]['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node in partition_contents[3][:10]:\n",
    "    print(corpus.iloc[node]['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node in partition_contents[8][:10]:\n",
    "    print(corpus.iloc[node]['clean_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
